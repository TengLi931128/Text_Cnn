{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis is a model of Text sentiment classification.\\nLi Teng\\n10.11.2021\\n\\n\\nThe process will be done in following step:\\n\\n1.load config\\n\\n2.build model\\n\\n3.load data and clean it.\\n\\n4.training and recording \\n\\n5.testing\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This is a model of Text sentiment classification.\n",
    "Li Teng\n",
    "10.11.2021\n",
    "\n",
    "\n",
    "The process will be done in following step:\n",
    "\n",
    "1.load config\n",
    "\n",
    "2.build model\n",
    "\n",
    "3.load data and clean it.\n",
    "\n",
    "4.training and recording \n",
    "\n",
    "5.testing\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from config import DefaultConfig\n",
    "from Text_Cnn import ConvNet, dynamical_padding\n",
    "import os\n",
    "from utils import load_flattened_documents, load_datasets\n",
    "from datasets_preprocessing import clean_datasets, Movie_Classif_Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "\n",
    "'''\n",
    "loading config \n",
    "'''\n",
    "Conf = DefaultConfig()\n",
    "\n",
    "BATCH_SIZE = Conf.batch_size\n",
    "Lr = Conf.lr\n",
    "EPOCHS = Conf.epochs\n",
    "DEVICE = Conf.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "step 2: build model\n",
    "'''\n",
    "Text_CNN = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "step 3: load data and preprocessing\n",
    "'''\n",
    "\n",
    "#load raw datasets\n",
    "data_root = os.path.join('Data', 'movies')\n",
    "documents = load_flattened_documents(data_root,None)\n",
    "documents = clean_datasets(documents)\n",
    "train, val, test = load_datasets(data_root)\n",
    "#load Train_Dataset\n",
    "Train_Dataset = Movie_Classif_Dataset(documents,train)\n",
    "#load into DataLoader\n",
    "Loader = DataLoader(dataset = Train_Dataset,\n",
    "                    batch_size = BATCH_SIZE,\n",
    "                    shuffle=True,\n",
    "                    collate_fn=dynamical_padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: teng_li (use `wandb login --relogin` to force relogin)\n",
      "wandb: wandb version 0.12.7 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/teng_li/Text_Cnn/runs/15ig2xno\" target=\"_blank\">stilted-wave-9</a></strong> to <a href=\"https://wandb.ai/teng_li/Text_Cnn\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, batch:0, loss:0.7643529176712036\n",
      "epoch:0, batch:100, loss:0.6867783069610596\n",
      "epoch:0, batch:200, loss:0.6926758289337158\n",
      "epoch:0, batch:300, loss:0.7586843371391296\n",
      "epoch:0, batch:400, loss:0.6166043281555176\n",
      "epoch:0, batch:500, loss:0.6673188209533691\n",
      "epoch:0, batch:600, loss:0.5911650657653809\n",
      "epoch:0, batch:700, loss:0.7405256628990173\n",
      "epoch:1, batch:0, loss:0.6578952074050903\n",
      "epoch:1, batch:100, loss:0.6113396883010864\n",
      "epoch:1, batch:200, loss:0.7237201929092407\n",
      "epoch:1, batch:300, loss:0.6108875274658203\n",
      "epoch:1, batch:400, loss:0.6910234689712524\n",
      "epoch:1, batch:500, loss:0.6951044797897339\n",
      "epoch:1, batch:600, loss:0.6917423605918884\n",
      "epoch:1, batch:700, loss:0.5566729307174683\n",
      "epoch:2, batch:0, loss:0.8171804547309875\n",
      "epoch:2, batch:100, loss:0.579620897769928\n",
      "epoch:2, batch:200, loss:0.6413412094116211\n",
      "epoch:2, batch:300, loss:0.6574481725692749\n",
      "epoch:2, batch:400, loss:0.7596308588981628\n",
      "epoch:2, batch:500, loss:0.6155985593795776\n",
      "epoch:2, batch:600, loss:0.46953970193862915\n",
      "epoch:2, batch:700, loss:1.1516022682189941\n",
      "epoch:3, batch:0, loss:0.3860871195793152\n",
      "epoch:3, batch:100, loss:1.3318634033203125\n",
      "epoch:3, batch:200, loss:0.16609656810760498\n",
      "epoch:3, batch:300, loss:0.5523155331611633\n",
      "epoch:3, batch:400, loss:0.44299593567848206\n",
      "epoch:3, batch:500, loss:0.22008028626441956\n",
      "epoch:3, batch:600, loss:0.247640460729599\n",
      "epoch:3, batch:700, loss:0.46452173590660095\n",
      "epoch:4, batch:0, loss:0.08492395281791687\n",
      "epoch:4, batch:100, loss:0.5020517110824585\n",
      "epoch:4, batch:200, loss:0.12398675829172134\n",
      "epoch:4, batch:300, loss:0.013973543420433998\n",
      "epoch:4, batch:400, loss:0.028026122599840164\n",
      "epoch:4, batch:500, loss:1.955392837524414\n",
      "epoch:4, batch:600, loss:0.026155099272727966\n",
      "epoch:4, batch:700, loss:0.8144919276237488\n",
      "epoch:5, batch:0, loss:0.015266552567481995\n",
      "epoch:5, batch:100, loss:0.019921137019991875\n",
      "epoch:5, batch:200, loss:0.0030941893346607685\n",
      "epoch:5, batch:300, loss:0.16849572956562042\n",
      "epoch:5, batch:400, loss:0.03224360942840576\n",
      "epoch:5, batch:500, loss:0.010251813568174839\n",
      "epoch:5, batch:600, loss:0.16407352685928345\n",
      "epoch:5, batch:700, loss:0.02565348520874977\n",
      "epoch:6, batch:0, loss:0.009761526249349117\n",
      "epoch:6, batch:100, loss:0.008231502957642078\n",
      "epoch:6, batch:200, loss:0.002639582846313715\n",
      "epoch:6, batch:300, loss:0.004372057504951954\n",
      "epoch:6, batch:400, loss:0.0006746236467733979\n",
      "epoch:6, batch:500, loss:0.0019363631727173924\n",
      "epoch:6, batch:600, loss:0.013573601841926575\n",
      "epoch:6, batch:700, loss:0.0018537454307079315\n",
      "epoch:7, batch:0, loss:0.00043959912727586925\n",
      "epoch:7, batch:100, loss:0.0010294977109879255\n",
      "epoch:7, batch:200, loss:0.0002910625480581075\n",
      "epoch:7, batch:300, loss:0.0006807171157561243\n",
      "epoch:7, batch:400, loss:0.0025521412026137114\n",
      "epoch:7, batch:500, loss:0.0014828466810286045\n",
      "epoch:7, batch:600, loss:0.013557987287640572\n",
      "epoch:7, batch:700, loss:0.00258330418728292\n",
      "epoch:8, batch:0, loss:0.0015925728948786855\n",
      "epoch:8, batch:100, loss:0.0006584443035535514\n",
      "epoch:8, batch:200, loss:0.00014977523824200034\n",
      "epoch:8, batch:300, loss:0.00013540926738642156\n",
      "epoch:8, batch:400, loss:0.0001031694482662715\n",
      "epoch:8, batch:500, loss:0.0005683909403160214\n",
      "epoch:8, batch:600, loss:9.232330921804532e-05\n",
      "epoch:8, batch:700, loss:0.0001248031621798873\n",
      "epoch:9, batch:0, loss:0.0002069257607217878\n",
      "epoch:9, batch:100, loss:0.00017062602273654193\n",
      "epoch:9, batch:200, loss:0.0001843982026912272\n",
      "epoch:9, batch:300, loss:0.0002118683187291026\n",
      "epoch:9, batch:400, loss:0.00015150241961237043\n",
      "epoch:9, batch:500, loss:0.0007541021914221346\n",
      "epoch:9, batch:600, loss:0.00023128844622988254\n",
      "epoch:9, batch:700, loss:5.7099616242339835e-05\n",
      "epoch:10, batch:0, loss:0.0001858861360233277\n",
      "epoch:10, batch:100, loss:5.101998249301687e-05\n",
      "epoch:10, batch:200, loss:7.253584772115573e-05\n",
      "epoch:10, batch:300, loss:0.0007493160665035248\n",
      "epoch:10, batch:400, loss:0.0010087821865454316\n",
      "epoch:10, batch:500, loss:0.0002423140686005354\n",
      "epoch:10, batch:600, loss:5.3702256991527975e-05\n",
      "epoch:10, batch:700, loss:6.574153667315841e-05\n",
      "epoch:11, batch:0, loss:3.528532761265524e-05\n",
      "epoch:11, batch:100, loss:0.0001231951464433223\n",
      "epoch:11, batch:200, loss:0.0001305251644225791\n",
      "epoch:11, batch:300, loss:0.00017128291074186563\n",
      "epoch:11, batch:400, loss:0.0002944247389677912\n",
      "epoch:11, batch:500, loss:0.00011860205995617434\n",
      "epoch:11, batch:600, loss:0.0007055796450003982\n",
      "epoch:11, batch:700, loss:5.507300375029445e-05\n",
      "epoch:12, batch:0, loss:0.00010221512638963759\n",
      "epoch:12, batch:100, loss:0.00017867806309368461\n",
      "epoch:12, batch:200, loss:0.00010710344213293865\n",
      "epoch:12, batch:300, loss:0.0002709810505621135\n",
      "epoch:12, batch:400, loss:0.00020602613221853971\n",
      "epoch:12, batch:500, loss:0.0001293336827075109\n",
      "epoch:12, batch:600, loss:0.00024916374241001904\n",
      "epoch:12, batch:700, loss:4.4642831198871136e-05\n",
      "epoch:13, batch:0, loss:6.866130570415407e-05\n",
      "epoch:13, batch:100, loss:0.0002147148916264996\n",
      "epoch:13, batch:200, loss:3.093428676947951e-05\n",
      "epoch:13, batch:300, loss:0.00022277190873865038\n",
      "epoch:13, batch:400, loss:4.041112697450444e-05\n",
      "epoch:13, batch:500, loss:9.476685954723507e-05\n",
      "epoch:13, batch:600, loss:0.0001774794072844088\n",
      "epoch:13, batch:700, loss:0.00035518736694939435\n",
      "epoch:14, batch:0, loss:0.0002797360939439386\n",
      "epoch:14, batch:100, loss:0.00034017645521089435\n",
      "epoch:14, batch:200, loss:0.0001074581450666301\n",
      "epoch:14, batch:300, loss:9.625410893931985e-05\n",
      "epoch:14, batch:400, loss:3.617927723098546e-05\n",
      "epoch:14, batch:500, loss:0.0003256486961618066\n",
      "epoch:14, batch:600, loss:0.00023504337877966464\n",
      "epoch:14, batch:700, loss:0.00013230997137725353\n",
      "epoch:15, batch:0, loss:0.00030301508377306163\n",
      "epoch:15, batch:100, loss:0.00015650471323169768\n",
      "epoch:15, batch:200, loss:4.1126222640741616e-05\n",
      "epoch:15, batch:300, loss:6.645600660704076e-05\n",
      "epoch:15, batch:400, loss:7.348830695264041e-05\n",
      "epoch:15, batch:500, loss:3.284159902250394e-05\n",
      "epoch:15, batch:600, loss:3.623873999458738e-05\n",
      "epoch:15, batch:700, loss:2.926540582848247e-05\n",
      "epoch:16, batch:0, loss:0.00023360317572951317\n",
      "epoch:16, batch:100, loss:6.746949657099321e-05\n",
      "epoch:16, batch:200, loss:8.767388499109074e-05\n",
      "epoch:16, batch:300, loss:0.0002611277741380036\n",
      "epoch:16, batch:400, loss:0.00017980019038077444\n",
      "epoch:16, batch:500, loss:2.610648880363442e-05\n",
      "epoch:16, batch:600, loss:0.00011752883438020945\n",
      "epoch:16, batch:700, loss:0.00021977633878123015\n",
      "epoch:17, batch:0, loss:5.2808249165536836e-05\n",
      "epoch:17, batch:100, loss:2.6642781449481845e-05\n",
      "epoch:17, batch:200, loss:0.00021626485977321863\n",
      "epoch:17, batch:300, loss:3.0397850423469208e-05\n",
      "epoch:17, batch:400, loss:0.0001110943267121911\n",
      "epoch:17, batch:500, loss:8.391979645239189e-05\n",
      "epoch:17, batch:600, loss:0.00011693430133163929\n",
      "epoch:17, batch:700, loss:7.473993173334748e-05\n",
      "epoch:18, batch:0, loss:7.313203241210431e-05\n",
      "epoch:18, batch:100, loss:0.00017985630256589502\n",
      "epoch:18, batch:200, loss:0.00020208224304951727\n",
      "epoch:18, batch:300, loss:7.527695561293513e-05\n",
      "epoch:18, batch:400, loss:9.339338430436328e-05\n",
      "epoch:18, batch:500, loss:3.898028808180243e-05\n",
      "epoch:18, batch:600, loss:3.898025897797197e-05\n",
      "epoch:18, batch:700, loss:0.00018171159899793565\n",
      "epoch:19, batch:0, loss:3.540451143635437e-05\n",
      "epoch:19, batch:100, loss:1.8417662431602366e-05\n",
      "epoch:19, batch:200, loss:3.021891097887419e-05\n",
      "epoch:19, batch:300, loss:4.231839193380438e-05\n",
      "epoch:19, batch:400, loss:0.00011252218973822892\n",
      "epoch:19, batch:500, loss:2.3781929485267028e-05\n",
      "epoch:19, batch:600, loss:7.533719326602295e-05\n",
      "epoch:19, batch:700, loss:0.00029178173281252384\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "step 4: training and recording \n",
    "'''\n",
    "def train(epochs,model,device,dataloader,Lr):\n",
    "    '''\n",
    "    Training model\n",
    "    '''    \n",
    "    loss_func = nn.NLLLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=Lr)\n",
    "    model.to(device)\n",
    "    #model.train()\n",
    "    for e in range(epochs):\n",
    "        for i,(x,y_hat) in enumerate(dataloader):\n",
    "            x = x.to(device)\n",
    "            y_hat = y_hat.to(device)\n",
    "            y = model(x)\n",
    "            loss = loss_func(y,y_hat)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if i%100 == 0:\n",
    "                print('epoch:{}, batch:{}, loss:{}'.format(e,i,loss.data))\n",
    "                wandb.log({\"loss\": loss})\n",
    "                # Optional\n",
    "                wandb.watch(model)\n",
    "    torch.save(model,'Text_Cnn.pth')\n",
    "\n",
    "wandb.init(project='Text_Cnn',entity='teng_li')\n",
    "train(EPOCHS,Text_CNN,DEVICE,Loader,Lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 166\n",
      "total: 200\n",
      "acc =  0.83\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "step 5: validation\n",
    "'''\n",
    "#load Val_Dataset\n",
    "Val_Dataset = Movie_Classif_Dataset(documents,val)\n",
    "#load into DataLoader\n",
    "Loader = DataLoader(dataset = Val_Dataset,\n",
    "                    batch_size = 1,\n",
    "                    shuffle=True)\n",
    "\n",
    "def validation(model,val_dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x,y in val_dataloader:\n",
    "            y_hat = model.predict(x)\n",
    "            if y[0] == y_hat:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    print('correct:',correct)\n",
    "    print('total:',total)\n",
    "    print('acc = ',correct/total)\n",
    "    \n",
    "validation(Text_CNN,Loader)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
